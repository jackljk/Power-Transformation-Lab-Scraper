# Wikipedia Extraction Profile
# --------------------------

# name for profile (For nicer identification in logs/results) Keep lowercase and use underscores/dashes
name: "energy_validation_website"

scraper:
  # URL to scrape
  url: "https://www.sciencedirect.com/science/article/pii/S0360544216311811?via%3Dihub"
  # filepath to pdf
  filepath: null
  
  # Information to extract
  prompt: 
    task_template: "pdf_default"
    text: |-
      Extract the data about " publicly available reanalysis datasets and the parameters most relevant to wind power synthesis" which is avaliable in the downloadable pdf file.

  
  # Additional context to help with scraping
  additional_context:
    format: "text"
    value: |-
      Use the PDF parsing action to parse and extract informations from downloaded pdf files.

  initial_actions:
    # - go_to_url: "https://en.wikipedia.org/wiki/Apple"
    # - scroll_down: 4000
    # - go_to_url: "https://en.wikipedia.org/wiki/List_of_Academy_Award%E2%80%93winning_films"

content_structure:
  Table-1:
    Institution/Model: str
    Released: str
    Coverage: str
    Spatial_Resolution: str
    Time_Resolution: str
    Wind_speed_heights: str
    Other_model_heights: str

########################################################################
# Optional: Specify the content structure for the scraper to use
# content_structure:
#   <content_type>:
#     <field_name>: <data_type>
#     <field_name>: <data_type>
#
# Example
# content_structure:
#   Film:
#     title: str
#     nominations: int
#     awards_won: int
#     best_picture: bool  # True if the film won the best picture award, False otherwise
#########################################################################
# Avalible Actions
# - scroll_down: <pixels>  # Scroll down the page by a specified number of pixels
# - scroll_up: <pixels>    # Scroll up the page by a specified number of pixels
# - go_to_url: <url>  # Navigate to a specific URL