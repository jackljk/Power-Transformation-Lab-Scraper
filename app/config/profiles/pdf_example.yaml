# Wikipedia Extraction Profile
# --------------------------

# name for profile (For nicer identification in logs/results) Keep lowercase and use underscores/dashes
name: "pdf_example"

scraper:
  # URL to scrape
  url: null
  # filepath to pdf
  filepath: "C:/Users/limja/Documents/Research/Power\ Lab/Power-Transformation-Lab-Scraper/data//energy_validation.pdf"
  
  # Information to extract
  prompt: 
    task_template: "pdf_default"
    text: |-
      Extract the data about " publicly available reanalysis datasets and the parameters most relevant to wind power synthesis" from the table in the PDF

  
  # Additional context to help with scraping
  additional_context:
    format: "text"
    value: |-
      The pdf is parsed as a Markdown file before being passed to the model.
      If encountering a character, uses utf-8 encoding to type the character.

  initial_actions:
    # - go_to_url: "https://en.wikipedia.org/wiki/Apple"
    # - scroll_down: 4000
    # - go_to_url: "https://en.wikipedia.org/wiki/List_of_Academy_Award%E2%80%93winning_films"

content_structure:
  Table-1:
    Institution/Model: str
    Released: str
    Coverage: str
    Spatial_Resolution: str
    Time_Resolution: str
    Wind_speed_heights: str
    Other_model_heights: str

########################################################################
# Optional: Specify the content structure for the scraper to use
# content_structure:
#   <content_type>:
#     <field_name>: <data_type>
#     <field_name>: <data_type>
#
# Example
# content_structure:
#   Film:
#     title: str
#     nominations: int
#     awards_won: int
#     best_picture: bool  # True if the film won the best picture award, False otherwise
#########################################################################
# Avalible Actions
# - scroll_down: <pixels>  # Scroll down the page by a specified number of pixels
# - scroll_up: <pixels>    # Scroll up the page by a specified number of pixels
# - go_to_url: <url>  # Navigate to a specific URL